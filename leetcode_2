Table: Customer

+-------------+---------+
| Column Name | Type    |
+-------------+---------+
| id          | int     |
| name        | varchar |
| referee_id  | int     |
+-------------+---------+
In SQL, id is the primary key column for this table.
Each row of this table indicates the id of a customer, their name, and the id of the customer who referred them.
 

Find the names of the customer that are not referred by the customer with id = 2.

Return the result table in any order.

The result format is in the following example.

 

Example 1:

Input: 
Customer table:
+----+------+------------+
| id | name | referee_id |
+----+------+------------+
| 1  | Will | null       |
| 2  | Jane | null       |
| 3  | Alex | 2          |
| 4  | Bill | null       |
| 5  | Zack | 1          |
| 6  | Mark | 2          |
+----+------+------------+
Output: 
+------+
| name |
+------+
| Will |
| Jane |
| Bill |
| Zack |
+------+

from pyspark import SparkConf, SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import *
from pyspark.sql.window import *

conf = SparkConf().setMaster("local[*]").setAppName("Scenerio-10")
sc = SparkContext(conf=conf)
sc.setLogLevel("ERROR")
spark = SparkSession.builder.getOrCreate()

data = [
    (1, "Will", None),
    (2, "Jane", None),
    (3, "Alex", 2),
    (4, "Bill", None),
    (5, "Zack", 1),
    (6, "Mark", 2)
]

# Define schema for the DataFrame
columns = ["id", "name", "referee_id"]

# Create the DataFrame
df = spark.createDataFrame(data, schema=columns)

#pyspark
df.show()
df_fil=df.filter((col("referee_id")!=2) | (col("referee_id").isNull())).select(col("name"))
df_fil.show()


#sparksql
df.createOrReplaceTempView("table")
sql_df=spark.sql("select name from table where referee_id != 2 or referee_id is Null")
sql_df.show()


#pandas
pandas_df= pd.DataFrame(data, columns=columns)
df_filter=pandas_df[(pandas_df["referee_id"].isnull()) | (pandas_df["referee_id"]!=2)]
print(df_filter)









